{"meta":{"title":"Sea Salt","subtitle":"Legends Never Die.","description":"be brave...","author":"海盐","url":"http://yoursite.com"},"pages":[{"title":"About me","date":"2017-03-19T07:51:24.000Z","updated":"2017-10-22T10:06:24.000Z","comments":false,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"EducationWork experienceSkillsBook List欢迎您捐赠本站，您的支持是我最大的动力！"},{"title":"Categories","date":"2017-03-19T09:05:49.000Z","updated":"2017-03-19T14:39:59.000Z","comments":false,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"Tagcloud","date":"2017-03-19T09:01:08.000Z","updated":"2017-03-19T14:40:14.000Z","comments":false,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Tensorflow Timeline介绍及简单使用","slug":"tf-timeline-tool","date":"2018-04-22T10:09:00.000Z","updated":"2018-04-22T12:53:34.641Z","comments":true,"path":"2018/04/22/tf-timeline-tool/","link":"","permalink":"http://yoursite.com/2018/04/22/tf-timeline-tool/","excerpt":"","text":"Blog的Github地址：https://github.com/liuyan731/blog 最近上线了一个图片分类的机器学习Python服务，但是在线上的性能并不是特别好，就开始进行痛苦的性能分析。今天分享一个简单但是非常实用的Tensorflow性能调优工具Timeline。 简介Tensorflow的Timeline模块是用于描述张量图一个工具，可以记录在会话中每个操作执行时间和资源分配及消耗的情况。 使用方法执行代码sess.run()加入参数options和run_metadatasess.run() 加入 option和run_metadata参数，然后创建timeline对象，并写入到timeline.json文件中 12345678910111213import tensorflow as tffrom tensorflow.python.client import timelinerun_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)run_metadata = tf.RunMetadata()predictions = use_sess.run(use_out, &#123;'DecodeJpeg/contents:0': image_file.file.getvalue()&#125;, options=run_options, run_metadata=run_metadata)# Create the Timeline object, and write it to a jsontl = timeline.Timeline(run_metadata.step_stats)ctf = tl.generate_chrome_trace_format()with open('timeline.json', 'w') as f: f.write(ctf) 查看timeline对象打开Google Chrome，转到该页面 chrome://tracing并加载该timeline.json文件。在该页面上可以每个操作的耗时，以及op的详细信息。 chrome 加载timeline.json文件后展示的运行图 2018/4/22 done 此文章也同步至个人Github博客","categories":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://yoursite.com/categories/Machine-Learning/"}],"tags":[{"name":"machine learning","slug":"machine-learning","permalink":"http://yoursite.com/tags/machine-learning/"},{"name":"tensorflow","slug":"tensorflow","permalink":"http://yoursite.com/tags/tensorflow/"}]},{"title":"使用Pushy进行APNs消息推送","slug":"How-To-Use-APNs-Pushy","date":"2017-12-05T15:11:00.000Z","updated":"2017-12-12T15:11:29.785Z","comments":true,"path":"2017/12/05/How-To-Use-APNs-Pushy/","link":"","permalink":"http://yoursite.com/2017/12/05/How-To-Use-APNs-Pushy/","excerpt":"","text":"最近对项目组的老的苹果IOS推送进行了升级修改。看了看苹果的接口文档，感觉自己直接来写一个保证稳定和高效的接口还是有点难度，同时为了避免重复造轮子（懒），囧….调研了一些开源常用的库之后，选择了Turo团队开发和维护的pushy。 APNs和Pushy苹果设备的消息推送是依靠苹果的APNs（Apple Push Notification service）服务的，APNs的官方简介如下： Apple Push Notification service (APNs) is the centerpiece of the remote notifications feature. It is a robust, secure, and highly efficient service for app developers to propagate information to iOS (and, indirectly, watchOS), tvOS, and macOS devices. IOS设备（tvOS、macOS）上的所有消息推送都需要经过APNs，APNs服务确实非常厉害，每天需要推送上百亿的消息，可靠、安全、高效。就算是微信和QQ这种用户级别的即时通讯app在程序没有启动或者后台运行过程中也是需要使用APNs的（当程序启动时，使用自己建立的长连接），只不过腾讯优化了整条从他们服务器到苹果服务器的线路而已，所以觉得推送要快（参考知乎）。 项目组老的苹果推送服务使用的是苹果以前的基于二进制socket的APNs，同时使用的是一个javapns的开源库，这个javapns貌似效果不是很好，在网上也有人有过讨论。javapns现在也停止维护DEPRECATED掉了。作者建议转向基于苹果新APNs服务的库。 苹果新APNs基于HTTP/2，通过连接复用，更加高效，当然还有其它方面的优化和改善，可以参考APNs的一篇介绍，讲解的比较清楚。 再说一下我们使用的Pushy，官方简介如下： Pushy is a Java library for sending APNs (iOS, macOS, and Safari) push notifications. It is written and maintained by the engineers at Turo……We believe that Pushy is already the best tool for sending APNs push notifications from Java applications, and we hope you’ll help us make it even better via bug reports and pull requests. Pushy的文档和说明很全，讨论也很活跃，作者基本有问必答，大部分疑问都可以找到答案，使用难度也不大。 使用Pushy进行APNs消息推送首先加入包12345&lt;dependency&gt; &lt;groupId&gt;com.turo&lt;/groupId&gt; &lt;artifactId&gt;pushy&lt;/artifactId&gt; &lt;version&gt;0.11.1&lt;/version&gt;&lt;/dependency&gt; 身份认证苹果APNs提供了两种认证的方式：基于JWT的身份信息token认证和基于证书的身份认证。Pushy也同样支持这两种认证方式，这里我们使用证书认证方式，关于token认证方式可以查看Pushy的文档。 如何获取苹果APNs身份认证证书可以查考官方文档。 Pushy使用123ApnsClient apnsClient = new ApnsClientBuilder() .setClientCredentials(new File(&quot;/path/to/certificate.p12&quot;), &quot;p12-file-password&quot;) .build(); ps. 这里的setClientCredentials函数也可以支持传入一个InputStream和证书密码。 同时也可以通过setApnsServer函数来指定是开发环境还是生产环境：123ApnsClient apnsClient = new ApnsClientBuilder().setApnsServer(ApnsClientBuilder.DEVELOPMENT_APNS_HOST) .setClientCredentials(new File(&quot;/path/to/certificate.p12&quot;), &quot;p12-file-password&quot;) .build(); Pushy是基于Netty的，通过ApnsClientBuilder我们可以根据需要来修改ApnsClient的连接数和EventLoopGroups的线程数。 1234EventLoopGroup eventLoopGroup = new NioEventLoopGroup(4);ApnsClient apnsClient = new ApnsClientBuilder() .setClientCredentials(new File(&quot;/path/to/certificate.p12&quot;), &quot;p12-file-password&quot;) .setConcurrentConnections(4).setEventLoopGroup(eventLoopGroup).build(); 关于连接数和EventLoopGroup线程数官网有如下的说明，简单来说，不要配置EventLoopGroups的线程数超过APNs连接数。 Because connections are bound to a single event loop (which is bound to a single thread), it never makes sense to give an ApnsClient more threads in an event loop than concurrent connections. A client with an eight-thread EventLoopGroup that is configured to maintain only one connection will use one thread from the group, but the other seven will remain idle. Opening a large number of connections on a small number of threads will likely reduce overall efficiency by increasing competition for CPU time. 关于消息的推送，注意一定要使用异步操作，Pushy发送消息会返回一个Netty Future对象，通过它可以拿到消息发送的情况。 123456789101112for (final ApnsPushNotification pushNotification : collectionOfPushNotifications) &#123; final Future sendNotificationFuture = apnsClient.sendNotification(pushNotification); sendNotificationFuture.addListener(new GenericFutureListener&lt;Future&lt;PushNotificationResponse&gt;&gt;() &#123; @Override public void operationComplete(final Future&lt;PushNotificationResponse&gt; future) throws Exception &#123; // This will get called when the sever has replied and returns immediately final PushNotificationResponse response = future.getNow(); &#125; &#125;);&#125; APNs服务器可以保证同时发送1500条消息，当超过这个限制时，Pushy会缓存消息，所以我们不必担心异步操作发送的消息过多（当我们的消息非常多，达到上亿时，我们也得做一些控制，避免缓存过大，内存不足，Pushy给出了使用Semaphore的解决方法）。 The APNs server allows for (at the time of this writing) 1,500 notifications in flight at any time. If we hit that limit, Pushy will buffer notifications automatically behind the scenes and send them to the server as in-flight notifications are resolved. In short, asynchronous operation allows Pushy to make the most of local resources (especially CPU time) by sending notifications as quickly as possible. 以上仅是Pushy的基本用法，在我们的生产环境中情况可能会更加复杂，我们可能需要知道什么时候所有推送都完成了，可能需要对推送成功消息进行计数，可能需要防止内存不足，也可能需要对不同的发送结果进行不同处理….不多说，上代码。 最佳实践参考Pushy的官方最佳实践，我们加入了如下操作： 通过Semaphore来进行流控，防止缓存过大，内存不足 通过CountDownLatch来标记消息是否发送完成 使用AtomicLong完成匿名内部类operationComplete方法中的计数 使用Netty的Future对象进行消息推送结果的判断 具体用法参考如下代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485public class IOSPush &#123; private static final Logger logger = LoggerFactory.getLogger(IOSPush.class); private static final ApnsClient apnsClient = null; private static final Semaphore semaphore = new Semaphore(10000); public void push(final List&lt;String&gt; deviceTokens, String alertTitle, String alertBody) &#123; long startTime = System.currentTimeMillis(); if (apnsClient == null) &#123; try &#123; EventLoopGroup eventLoopGroup = new NioEventLoopGroup(4); apnsClient = new ApnsClientBuilder().setApnsServer(ApnsClientBuilder.DEVELOPMENT_APNS_HOST) .setClientCredentials(new File(&quot;/path/to/certificate.p12&quot;), &quot;p12-file-password&quot;) .setConcurrentConnections(4).setEventLoopGroup(eventLoopGroup).build(); &#125; catch (Exception e) &#123; logger.error(&quot;ios get pushy apns client failed!&quot;); e.printStackTrace(); &#125; &#125; long total = deviceTokens.size(); final CountDownLatch latch = new CountDownLatch(deviceTokens.size()); final AtomicLong successCnt = new AtomicLong(0); long startPushTime = System.currentTimeMillis(); for (String deviceToken : deviceTokens) &#123; ApnsPayloadBuilder payloadBuilder = new ApnsPayloadBuilder(); payloadBuilder.setAlertBody(alertBody); payloadBuilder.setAlertTitle(alertTitle); String payload = payloadBuilder.buildWithDefaultMaximumLength(); final String token = TokenUtil.sanitizeTokenString(deviceToken); SimpleApnsPushNotification pushNotification = new SimpleApnsPushNotification(token, &quot;com.example.myApp&quot;, payload); try &#123; semaphore.acquire(); &#125; catch (InterruptedException e) &#123; logger.error(&quot;ios push get semaphore failed, deviceToken:&#123;&#125;&quot;, deviceToken); e.printStackTrace(); &#125; final Future&lt;PushNotificationResponse&lt;SimpleApnsPushNotification&gt;&gt; future = apnsClient.sendNotification(pushNotification); future.addListener(new GenericFutureListener&lt;Future&lt;PushNotificationResponse&gt;&gt;() &#123; @Override public void operationComplete(Future&lt;PushNotificationResponse&gt; pushNotificationResponseFuture) throws Exception &#123; if (future.isSuccess()) &#123; final PushNotificationResponse&lt;SimpleApnsPushNotification&gt; response = future.getNow(); if (response.isAccepted()) &#123; successCnt.incrementAndGet(); &#125; else &#123; Date invalidTime = response.getTokenInvalidationTimestamp(); logger.error(&quot;Notification rejected by the APNs gateway: &quot; + response.getRejectionReason()); if (invalidTime != null) &#123; logger.error(&quot;\\t…and the token is invalid as of &quot; + response.getTokenInvalidationTimestamp()); &#125; &#125; &#125; else &#123; logger.error(&quot;send notification device token=&#123;&#125; is failed &#123;&#125; &quot;, token, future.cause().getMessage()); &#125; latch.countDown(); semaphore.release(); &#125; &#125;); &#125; try &#123; latch.await(20, TimeUnit.SECONDS); &#125; catch (InterruptedException e) &#123; logger.error(&quot;ios push latch await failed!&quot;); e.printStackTrace(); &#125; long endPushTime = System.currentTimeMillis(); logger.info(&quot;test pushMessage success. [共推送&quot; + total + &quot;个][成功&quot; + (successCnt.get()) + &quot;个], totalcost= &quot; + (endPushTime - startTime) + &quot;, pushCost=&quot; + (endPushTime - startPushTime)); &#125;&#125; 关于多线程调用client Pushy ApnsClient是线程安全的，可以使用多线程来调用 关于创建多个client 创建多个client是可以加快发送速度的，但是提升并不大，作者建议： ApnsClient instances are designed to stick around for a long time. They’re thread-safe and can be shared between many threads in a large application. We recommend creating a single client (per APNs certificate/key), then keeping that client around for the lifetime of your application. 关于APNs响应信息（错误信息） 可以查看官网的error code表格（链接），了解出错情况，及时调整。 Pushy性能作者在Google讨论组中说Pushy推送可以单核单线程达到10k/s-20k/s，如下图所示： 作者关于创建多client的建议及Pushy性能描述 但是可能是网络或其他原因，我的测试结果没有这么好，把测试结果贴出来，仅供参考（时间ms）： ps. 由于是测试，没有大量的设备可以用于群发推送测试，所以以往一个设备发送多条推送替代。这里短时间往一个设备发送大量的推送，APNs会报TooManyRequests错误，Too many requests were made consecutively to the same device token。所以会有少量消息无法发出。 ps. 这里的推送时间，没有加上client初始化的时间。 ps. 消息推送时间与被推消息的大小有关系，这里我在测试时没有控制消息变量（都是我瞎填的，都是很短的消息）所以数据仅供参考。 ConcurrentConnections: 1, EventLoopGroup Thread: 1 推送1个设备 推送13个设备 同一设备推100条 同一设备推1000条 平均推送成功(个) 1 13 100 998 平均推送耗时(ms) 222 500 654 3200 ConcurrentConnections: 5, EventLoopGroup Thread: 1 推送1个设备 推送13个设备 同一设备推100条 同一设备推1000条 平均推送成功(个) 1 13 100 999 平均推送耗时(ms) 310 330 1600 1200 ConcurrentConnections: 4, EventLoopGroup Thread: 4 推送1个设备 推送13个设备 同一设备推100条 同一设备推1000条 平均推送成功(个) 1 13 100 999 平均推送耗时(ms) 250 343 700 1700 关于性能优化也可以看看官网作者的建议：Threads, concurrent connections, and performance 大家有测试的数据也可以分享出来一起讨论一下。 今天（12.11）又测了一下，推送给3个设备，每个重复推送1000条，共3000条，结果如下（时间为ms）： thread/connection No.1 No.2 No.3 No.4 No.5 No.6 No.7 No.8 No.9 No.10 Avg 1/1 12903 12782 10181 10393 11292 13608 - - - - 11859.8 4/4 2861 3289 6258 5488 6649 6113 7042 5393 4591 7269 5495.3 20/20 1575 1456 1640 2761 2321 2154 1796 1634 2440 2114 1989.1 40/40 1535 2134 3312 2311 1553 2088 1734 1834 1530 1724 1975.5 同时测了一下，给这3个设备重复推送100000条消息，共300000条的时间，结果如下（时间为ms）： thread/connection No.1 20/20 43547 思考苹果APNs一直在更新优化，一致在拥抱新技术（HTTP/2，JWT等），是一个非常了不起的服务。 自己来直接调用APNs服务来达到生成环境要求还是有点困难。Turo给我们提供了一个很好的Java库：Pushy。Pushy还有一些其他的功能与用法（Metrics、proxy、Logging…），总体来说还是非常不错的。 同时感觉我们使用Pushy还可以调优… 2017/12/07 done 此文章也同步至个人Github博客","categories":[{"name":"Web","slug":"Web","permalink":"http://yoursite.com/categories/Web/"}],"tags":[{"name":"apns","slug":"apns","permalink":"http://yoursite.com/tags/apns/"},{"name":"pushy","slug":"pushy","permalink":"http://yoursite.com/tags/pushy/"},{"name":"apple","slug":"apple","permalink":"http://yoursite.com/tags/apple/"}]},{"title":"Tensorflow模型的保存与恢复加载","slug":"Tensorflow-Model-Save-And-Restore","date":"2017-11-25T06:06:04.000Z","updated":"2017-11-25T15:50:34.000Z","comments":true,"path":"2017/11/25/Tensorflow-Model-Save-And-Restore/","link":"","permalink":"http://yoursite.com/2017/11/25/Tensorflow-Model-Save-And-Restore/","excerpt":"","text":"近期做了一些反垃圾的工作，除了使用常用的规则匹配过滤等手段，也采用了一些机器学习方法进行分类预测。我们使用TensorFlow进行模型的训练，训练好的模型需要保存，预测阶段我们需要将模型进行加载还原使用，这就涉及TensorFlow模型的保存与恢复加载。 总结一下Tensorflow常用的模型保存方式。 保存checkpoint模型文件（.ckpt）首先，TensorFlow提供了一个非常方便的api，tf.train.Saver()来保存和还原一个机器学习模型。 模型保存使用tf.train.Saver()来保存模型文件非常方便，下面是一个简单的例子： 12345678910111213141516171819202122import tensorflow as tfimport osdef save_model_ckpt(ckpt_file_path): x = tf.placeholder(tf.int32, name=&apos;x&apos;) y = tf.placeholder(tf.int32, name=&apos;y&apos;) b = tf.Variable(1, name=&apos;b&apos;) xy = tf.multiply(x, y) op = tf.add(xy, b, name=&apos;op_to_store&apos;) sess = tf.Session() sess.run(tf.global_variables_initializer()) path = os.path.dirname(os.path.abspath(ckpt_file_path)) if os.path.isdir(path) is False: os.makedirs(path) tf.train.Saver().save(sess, ckpt_file_path) # test feed_dict = &#123;x: 2, y: 3&#125; print(sess.run(op, feed_dict)) 程序生成并保存四个文件（在版本0.11之前只会生成三个文件：checkpoint, model.ckpt, model.ckpt.meta） checkpoint 文本文件，记录了模型文件的路径信息列表 model.ckpt.data-00000-of-00001 网络权重信息 model.ckpt.index .data和.index这两个文件是二进制文件，保存了模型中的变量参数（权重）信息 model.ckpt.meta 二进制文件，保存了模型的计算图结构信息（模型的网络结构）protobuf 以上是tf.train.Saver().save()的基本用法，save()方法还有很多可配置的参数： 1tf.train.Saver().save(sess, ckpt_file_path, global_step=1000) 加上global_step参数代表在每1000次迭代后保存模型，会在模型文件后加上”-1000”，model.ckpt-1000.index, model.ckpt-1000.meta, model.ckpt.data-1000-00000-of-00001 每1000次迭代保存一次模型，但是模型的结构信息文件不会变，就只用1000次迭代时保存一下，不用相应的每1000次保存一次，所以当我们不需要保存meta文件时，可以加上write_meta_graph=False参数，如下： 1tf.train.Saver().save(sess, ckpt_file_path, global_step=1000, write_meta_graph=False) 如果想每两小时保存一次模型，并且只保存最新的4个模型，可以加上使用max_to_keep（默认值为5，如果想每训练一个epoch就保存一次，可以将其设置为None或0，但是没啥用不推荐）, keep_checkpoint_every_n_hours参数，如下：1tf.train.Saver().save(sess, ckpt_file_path, max_to_keep=4, keep_checkpoint_every_n_hours=2) 同时在tf.train.Saver()类中，如果我们不指定任何信息，则会保存所有的参数信息，我们也可以指定部分想要保存的内容，例如只保存x, y参数（可传入参数list或dict）：1tf.train.Saver([x, y]).save(sess, ckpt_file_path) ps. 在模型训练过程中需要在保存后拿到的变量或参数名属性name不能丢，不然模型还原后不能通过get_tensor_by_name()获取。 模型加载还原针对上面的模型保存例子，还原模型的过程如下：123456789101112131415161718192021import tensorflow as tfdef restore_model_ckpt(ckpt_file_path): sess = tf.Session() saver = tf.train.import_meta_graph(&apos;./ckpt/model.ckpt.meta&apos;) # 加载模型结构 saver.restore(sess, tf.train.latest_checkpoint(&apos;./ckpt&apos;)) # 只需要指定目录就可以恢复所有变量信息 # 直接获取保存的变量 print(sess.run(&apos;b:0&apos;)) # 获取placeholder变量 input_x = sess.graph.get_tensor_by_name(&apos;x:0&apos;) input_y = sess.graph.get_tensor_by_name(&apos;y:0&apos;) # 获取需要进行计算的operator op = sess.graph.get_tensor_by_name(&apos;op_to_store:0&apos;) # 加入新的操作 add_on_op = tf.multiply(op, 2) ret = sess.run(add_on_op, &#123;input_x: 5, input_y: 5&#125;) print(ret) 首先还原模型结构，然后还原变量（参数）信息，最后我们就可以获得已训练的模型中的各种信息了（保存的变量、placeholder变量、operator等），同时可以对获取的变量添加各种新的操作（见以上代码注释）。 并且，我们也可以加载部分模型，在此基础上加入其它操作，具体可以参考官方文档和demo。 针对ckpt模型文件的保存与还原，stackoverflow上有一个回答解释比较清晰，可以参考。 同时cv-tricks.com上面的TensorFlow模型保存与恢复的教程也非常好，可以参考。 《tensorflow 1.0 学习：模型的保存与恢复(Saver)》有一些Saver使用技巧。 保存单个模型文件（.pb）我自己运行过Tensorflow的inception-v3的demo，发现运行结束后会生成一个.pb的模型文件，这个文件是作为后续预测或迁移学习使用的，就一个文件，非常炫酷，也十分方便。 这个过程的主要思路是graph_def文件中没有包含网络中的Variable值（通常情况存储了权重），但是却包含了constant值，所以如果我们能把Variable转换为constant（使用graph_util.convert_variables_to_constants()函数），即可达到使用一个文件同时存储网络架构与权重的目标。 ps：这里.pb是模型文件的后缀名，当然我们也可以用其它的后缀（使用.pb与google保持一致 ╮(╯▽╰)╭） 模型保存同样根据上面的例子，一个简单的demo： 123456789101112131415161718192021222324252627import tensorflow as tfimport osfrom tensorflow.python.framework import graph_utildef save_mode_pb(pb_file_path): x = tf.placeholder(tf.int32, name=&apos;x&apos;) y = tf.placeholder(tf.int32, name=&apos;y&apos;) b = tf.Variable(1, name=&apos;b&apos;) xy = tf.multiply(x, y) # 这里的输出需要加上name属性 op = tf.add(xy, b, name=&apos;op_to_store&apos;) sess = tf.Session() sess.run(tf.global_variables_initializer()) path = os.path.dirname(os.path.abspath(pb_file_path)) if os.path.isdir(path) is False: os.makedirs(path) # convert_variables_to_constants 需要指定output_node_names，list()，可以多个 constant_graph = graph_util.convert_variables_to_constants(sess, sess.graph_def, [&apos;op_to_store&apos;]) with tf.gfile.FastGFile(pb_file_path, mode=&apos;wb&apos;) as f: f.write(constant_graph.SerializeToString()) # test feed_dict = &#123;x: 2, y: 3&#125; print(sess.run(op, feed_dict)) 程序生成并保存一个文件 model.pb 二进制文件，同时保存了模型网络结构和参数（权重）信息 模型加载还原针对上面的模型保存例子，还原模型的过程如下： 1234567891011121314151617181920import tensorflow as tffrom tensorflow.python.platform import gfiledef restore_mode_pb(pb_file_path): sess = tf.Session() with gfile.FastGFile(pb_file_path, &apos;rb&apos;) as f: graph_def = tf.GraphDef() graph_def.ParseFromString(f.read()) sess.graph.as_default() tf.import_graph_def(graph_def, name=&apos;&apos;) print(sess.run(&apos;b:0&apos;)) input_x = sess.graph.get_tensor_by_name(&apos;x:0&apos;) input_y = sess.graph.get_tensor_by_name(&apos;y:0&apos;) op = sess.graph.get_tensor_by_name(&apos;op_to_store:0&apos;) ret = sess.run(op, &#123;input_x: 5, input_y: 5&#125;) print(ret) 模型的还原过程与checkpoint差不多一样。 CSDN《将TensorFlow的网络导出为单个文件》上介绍了TensorFlow保存单个模型文件的方式，大同小异，可以看看。 思考模型的保存与加载只是TensorFlow中最基础的部分之一，虽然简单但是也必不可少，在实际运用中还需要注意模型何时保存，哪些变量需要保存，如何设计加载实现迁移学习等等问题。 同时TensorFlow的函数和类都在一直变化更新，以后也有可能出现更丰富的模型保存和还原的方法。 选择保存为checkpoint或单个pb文件视业务情况而定，没有特别大的差别。checkpoint保存感觉会更加灵活一些，pb文件更适合线上部署吧（个人看法）。 以上完整代码：github 2017/11/25 done","categories":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://yoursite.com/categories/Machine-Learning/"}],"tags":[{"name":"machine learning","slug":"machine-learning","permalink":"http://yoursite.com/tags/machine-learning/"},{"name":"tensorflow","slug":"tensorflow","permalink":"http://yoursite.com/tags/tensorflow/"}]},{"title":"使用CXF调用Web Service服务","slug":"Call-Webservice-Service","date":"2017-11-18T11:06:42.000Z","updated":"2017-11-19T13:42:19.000Z","comments":true,"path":"2017/11/18/Call-Webservice-Service/","link":"","permalink":"http://yoursite.com/2017/11/18/Call-Webservice-Service/","excerpt":"","text":"工作也快半年了，时间很快，发现自己越来越懒了，书都堆灰了…平时工作虽忙但是周末不忙啊哈哈，看了zhoumorvan大神的博客和身边给力的小伙伴们，决定以后还是多看看多写写多分享。 记录是一个极好的习惯，我们会的知识中，有很大一部分其实是相对碎片的，很容易忘记。将它们整理并记下来是一个结构化知识的过程，也是一个整理和总结的过程。 工作第一篇，来个极简的：最近接入了人口信息应用平台的Web Service服务，第一次接触，就说一说使用CFX来调用Web Service服务的方式（没写如何发布Web Service服务，因为没做，可参考CXF和Spring整合发布和基于Maven在Spring中集成CXF Web Service框架）。 CXF调用Web Service服务1、下载CXF，解压即用（环境变量） 2、主要使用wadl2java这个工具，将Web Service发布的服务生成客户端java代码1wsdl2java -encoding utf-8 -p com.test.nciic -d D:\\\\src -all NciicServices.wsdl encoding：编码 p：package（这个包的结构需要注意，需要与代码中的包结构一致） d：代码生成目录 3、通过CXF的JaxWsProxyFactoryBean类来调用Web Service服务12345JaxWsProxyFactoryBean factory = new JaxWsProxyFactoryBean();factory.setServiceClass(NciicServicesPortType.class);factory.setAddress(\"https://ws.nciic.org.cn/nciic_ws/services/NciicServices\");private NciicServicesPortType client = (NciicServicesPortType) factory.create();String responseXmlStr = client.nciicCheck(nciicAuthKey, requestXmlStr); // 调用nciic服务 也可以集成在spring mvc中123456789101112131415161718&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:jaxws=\"http://cxf.apache.org/jaxws\" xmlns:jaxrs=\"http://cxf.apache.org/jaxrs\" xmlns:cxf=\"http://cxf.apache.org/core\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://cxf.apache.org/jaxrs http://cxf.apache.org/schemas/jaxrs.xsd http://cxf.apache.org/jaxws http://cxf.apache.org/schemas/jaxws.xsd http://cxf.apache.org/core http://cxf.apache.org/schemas/core.xsd\"&gt; &lt;!-- 使用&lt;jaxws:clietn&gt;调用服务端 jaxws:client内部使用JaxWsProxyFactoryBean方式 serviceClass:指定portType地址（需要使用wsdl2java工具生成） --&gt; &lt;jaxws:client id=\"client\" address=\"https://ws.nciic.org.cn/nciic_ws/services/NciicServices\" serviceClass=\"com.test.nciic.NciicServicesPortType\"&gt; &lt;/jaxws:client&gt;&lt;/beans&gt; 12345public void testCxfSpringClient()&#123; //从Spring容器中取出portType NciicServicesPortType client = (NciicServicesPortType) applicationContext.getBean(\"client\"); String responseXmlStr = client.nciicCheck(nciicAuthKey, requestXmlStr); // 调用nciic服务&#125; 这里的NciicServicesPortType是CXF生成的Web Service接口类，里面定义了wsdl文件所描述的所有服务接口，形式如下：1234567891011121314151617181920/** * This class was generated by Apache CXF 3.1.13 * 2017-10-27T17:18:40.243+08:00 * Generated source version: 3.1.13 * */@WebService(targetNamespace = \"https://api.nciic.org.cn/NciicServices\", name = \"NciicServicesPortType\")@XmlSeeAlso(&#123;ObjectFactory.class&#125;)public interface NciicServicesPortType &#123;@WebResult(name = \"out\", targetNamespace = \"https://api.nciic.org.cn/NciicServices\") @RequestWrapper(localName = \"nciicCheck\", targetNamespace = \"https://api.nciic.org.cn/NciicServices\", className = \"com.test.nciic.NciicCheck\") @WebMethod @ResponseWrapper(localName = \"nciicCheckResponse\", targetNamespace = \"https://api.nciic.org.cn/NciicServices\", className = \"com.test.nciic.NciicCheckResponse\") public String nciicCheck( @WebParam(name = \"inLicense\", targetNamespace = \"https://api.nciic.org.cn/NciicServices\") String inLicense, @WebParam(name = \"inConditions\", targetNamespace = \"https://api.nciic.org.cn/NciicServices\") String inConditions );&#125; PS：Nciic这个是个自签名（或CNNIC证书）的https，还需要安装它网站的证书，参考StevenLian这个博客。附一个java添加证书信任列表的静态代码块：123456789101112131415static &#123; javax.net.ssl.HttpsURLConnection.setDefaultHostnameVerifier( new javax.net.ssl.HostnameVerifier() &#123; @Override public boolean verify(String hostname, javax.net.ssl.SSLSession sslSession) &#123; //域名或ip地址 if (hostname.equals(\"ws.nciic.org.cn\")) &#123; return true; &#125; return false; &#125; &#125;); System.setProperty(\"javax.net.ssl.trustStore\", \"C:\\\\jssecacerts\"); System.setProperty(\"javax.net.ssl.trustStorePassword\", \"changeit\"; &#125; PS：Nciic这个服务挺慢的（200ms），还挺贵的（按次收费）…我们在调用时加入memcache缓存，避免短时相同请求重复调用，并且将验证通过的结果写入到数据库中，先查缓存和数据库最后再用第三方服务。 思考Web Service通过基于XML的SOAP来表示数据和请求，低耦合，在接口的发布和复用性上确实还行，接口的可读性也可以，但是确实还是没有调Http服务的api接口方便，很多国企和国家的对外服务貌似Web Service用的很多，但是在互联网公司貌似用的很少。Nciic服务使用Xml做请求和返回方式还是没有json方便，orz。 2017/11/18 done","categories":[{"name":"Web","slug":"Web","permalink":"http://yoursite.com/categories/Web/"}],"tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"},{"name":"web","slug":"web","permalink":"http://yoursite.com/tags/web/"}]},{"title":"栈和队列的相互实现","slug":"Stack-Queue","date":"2017-03-25T05:20:42.000Z","updated":"2017-03-25T05:36:51.000Z","comments":true,"path":"2017/03/25/Stack-Queue/","link":"","permalink":"http://yoursite.com/2017/03/25/Stack-Queue/","excerpt":"","text":"使用两个栈实现一个队列思路：使用两个栈来实现一个队列，插入操作使用Stack1来完成，删除操作使用Satck2，当Stack2为空的时候，将Stack1中所有的数据转移到Stack2中12345678910111213141516171819202122232425262728public class QueueImplementByTwoStacks &#123; private Stack stack1; private Stack stack2; public Q088QueueImplementByTwoStacks() &#123; stack1 = new Stack&lt;&gt;(); stack2 = new Stack&lt;&gt;(); &#125; public void offer(int o) &#123; // 入队操作在stack1中进行 stack1.push(o); &#125; public int poll() &#123; // 出队操作 int ret = 0; if (!stack2.isEmpty()) &#123; //不为空的时候直接弹出stack2的栈顶 ret = stack2.pop(); &#125; else &#123; //为空的时候将stack1中所有数据转移到stack2中 while(!stack1.isEmpty()) &#123; stack2.push(stack1.pop()); &#125; if(!stack2.isEmpty()) &#123; ret = stack2.pop(); &#125; &#125; return ret; &#125;&#125; 使用两个队列实现一个栈思路：用两个队列实现一个栈，在入栈操作时只将元素插入到非空队列中，空的队列用来做出栈操作，出栈时要得到的元素是非空队列的最后一个元素，将非空队列（size为n）的前n-1个元素转移到空队列中，第n个元素即为出栈元素。123456789101112131415161718192021222324252627282930313233343536373839public class StackImplementByTwoQueues &#123; private Queue queue1; private Queue queue2; public StackImplementByTwoQueues() &#123; queue1 = new LinkedList&lt;&gt;(); queue2 = new LinkedList&lt;&gt;(); &#125; public void push(int o) &#123; //push操作只在非空的队列中进行 if(queue1.isEmpty() &amp;&amp; queue2.isEmpty()) &#123; queue1.offer(o); &#125; if(!queue1.isEmpty()) &#123; queue1.offer(o); &#125; else if(!queue2.isEmpty()) &#123; queue2.offer(o); &#125; &#125; public int pop() throws Exception &#123; //将非空队列的中的数据转移到空队列中，留下最后一个作为栈pop的元素 int ret = 0; if(queue1.isEmpty() &amp;&amp; queue2.isEmpty()) &#123; throw new Exception(\"栈为空\"); &#125; else &#123; if(queue2.isEmpty()) &#123; while(queue1.size() &gt; 1) &#123; queue2.offer(queue1.poll()); &#125; ret = queue1.poll(); &#125; else if(queue1.isEmpty()) &#123; while(queue2.size() &gt; 1) &#123; queue1.offer(queue2.poll()); &#125; ret = queue2.poll(); &#125; &#125; return ret; &#125;&#125;","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"http://yoursite.com/categories/Algorithm/"}],"tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"},{"name":"algorithm","slug":"algorithm","permalink":"http://yoursite.com/tags/algorithm/"},{"name":"stack","slug":"stack","permalink":"http://yoursite.com/tags/stack/"},{"name":"queue","slug":"queue","permalink":"http://yoursite.com/tags/queue/"}]},{"title":"找出数组中出现次数最多的k个元素","slug":"Top-K-In-Array","date":"2017-03-22T14:21:42.000Z","updated":"2017-03-22T16:45:32.000Z","comments":true,"path":"2017/03/22/Top-K-In-Array/","link":"","permalink":"http://yoursite.com/2017/03/22/Top-K-In-Array/","excerpt":"","text":"题目：给一个非空数组，求数组中出现次数最多的k个元素。例如给出数组[1, 1, 1, 2, 2, 3]和k=2，返回[1, 2] 思路1使用HashMap来对数组中的元素计数并存储，然后使用HashMap中的value构造大顶堆，取k次大顶堆的堆顶元素，同时调整大顶堆堆，取出value对应的key值。 123456789101112131415 // 使用HashMap+大顶堆来实现（取堆顶的最大k个元素）public static List topKFrequent(int[] nums, int k) &#123; Map&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(); for (int i : nums) &#123; map.put(i, map.containsKey(i) ? map.get(i) + 1 : 1); &#125; // 使用java自带的PriorityQueue类来实现，PriorityQueue是优先队列，实际上是一个小顶堆 PriorityQueue&lt;Map.Entry&lt;Integer, Integer&gt;&gt; pq = new PriorityQueue&lt;&gt;((o1, o2) -&gt; o2.getValue() - o1.getValue()); // 改变排序的方法，使用value作为判断 pq.addAll(map.entrySet()); List ret = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; k; i++) &#123; ret.add(pq.poll().getKey());// 每次都会去取堆顶的元素，每弹出一个元素都会重新调整堆 &#125; return ret;&#125; 时间复杂度O(N+klgk+(N-k)lgk) = O(Nlgk)，N：遍历数组，klgk：建堆，(N-k)lgk：剩余N-k个元素插入堆 思路二使用桶排序的思想，将出现次数为count的元素放入bucket[count]中，然后从bucket的index从大到小遍历。（这里需要注意的是有些出现次数一样的元素，所以我们的bucket数组需要定义成集合数组）123456789101112131415161718192021222324// 使用桶排序的思想public static List topKFrequent2(int[] nums, int k) &#123; List[] bucket = new ArrayList[nums.length + 1]; // 定义一个链表的数组，主要是为了解决一个频数出现多次的情况 Map&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(); for (int i : nums) &#123; map.put(i, map.containsKey(i) ? map.get(i) + 1 : 1); &#125; for (int key : map.keySet()) &#123; int frequency = map.get(key); if (bucket[frequency] == null) &#123; bucket[frequency] = new ArrayList&lt;&gt;(); &#125; bucket[frequency].add(key); &#125; List ret = new ArrayList&lt;&gt;(); for (int i = bucket.length - 1; i &gt;= 0 &amp;&amp; ret.size() &lt; k; i--) &#123; if (bucket[i] != null) &#123; ret.addAll(bucket[i]); &#125; &#125; return ret;&#125; 时间复杂度O(n)空间换时间","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"http://yoursite.com/categories/Algorithm/"}],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"http://yoursite.com/tags/algorithm/"}]},{"title":"MySQL数据库的两种存储引擎概要","slug":"DB-Storage-Engine","date":"2017-03-22T14:12:42.000Z","updated":"2017-03-22T16:15:52.000Z","comments":true,"path":"2017/03/22/DB-Storage-Engine/","link":"","permalink":"http://yoursite.com/2017/03/22/DB-Storage-Engine/","excerpt":"","text":"MyISAM和InnoDB作为MySQL的两种主要的存储引擎（在MySql5.5以后版本，Mysql默认采用的是InnoDB） 主要区别 MyISAM不支持事务处理（原子性操作）等高级处理，而InnoDB类型支持（InnoDB的AUTOCOMIIT是打开的） MyISAM表不支持外键； 在执行update、insert、delete等操作时MyISAM会锁表，InnoDB只会锁行（InnoDB琐行也不是绝对的，假如执行一个Sql语句时MySql不能确定要扫描的范围，InnoDB也会锁全表，例如：update table set num=1 where name like “%aaa%”） MyISAM类型强调的是性能，执行的速度比InnoDB要快 InnoDB不能保存表的具体行数，当需要获取表的行数时需要扫描整个表来计算 InnoDB不支持全文索引，MyISAM支持（建立倒排索引） 思考因此，当数据库有大量的写入、更新操作而查询操作较少时或者对数据的完整性要求较高的时候选用InnoDB，而当数据库主要以查询为主而相比较而言更新和写入比较少，并且业务方面数据的完整性要求不那么严格就选用MyISAM表。（MyISAM表的查询操作效率和速度都比InnoDB要快）","categories":[{"name":"Database","slug":"Database","permalink":"http://yoursite.com/categories/Database/"}],"tags":[{"name":"database","slug":"database","permalink":"http://yoursite.com/tags/database/"},{"name":"principle","slug":"principle","permalink":"http://yoursite.com/tags/principle/"}]},{"title":"浅析Hash表和HashMap的Hash实现","slug":"Hash-HashMap","date":"2017-03-21T15:00:42.000Z","updated":"2017-03-22T14:38:36.000Z","comments":true,"path":"2017/03/21/Hash-HashMap/","link":"","permalink":"http://yoursite.com/2017/03/21/Hash-HashMap/","excerpt":"","text":"散列表（Hash表）顺序查找、折半查找、树形结构中的查找，都是基于关键字的比较操作。散列表是摆脱“比较”操作的查找方式。散列表通过关键字和其存储位置之间建立某种关系：若结构中存在关键字和K相等的记录，则必定在f(K)的存储位置上，因此不需要比较就可以直接取得所查记录，称这个对应关系f为散列函数（hash函数），按这个思路建立保存记录的查找表称为哈希表。 散列在关键字及其存储位置之间建立某种关系，基于关键字完成记录的访问，既包含了数据元素的存储过程，也能实现数据元素的查找过程。 不同的关键字可能得到同一个散列地址（存储地址），即：key1 != key2，而f(key1) = f(key2)，这种现象称为==hash冲突==。将每个关键字映射到哈希表中唯一位置的哈希函数成为理想哈希函数（perfect hashing function）。理想哈希函数不会引起冲突，对表中所有的元素访问的时间都为O(1)。 多数情况下找不到理想hash函数，尽量找一个好的哈希函数，尽量避免hash冲突。 常用的hash函数构造方法 直接定址法：取关键字或关键字的某个线性函数值作为散列地址 数值分析法：一般取大一点的素数 平方取中法：计算关键字值再取中间r位形成一个2^r的表 除留余数法：取关键字被某个不大于散列表表长m的数p除后所得的余数为散列地址。即 H(key) = key % p, p&lt;=m 。不仅可以对关键字直接取模，也可在折叠、平方取中等运算之后取模。对p的选择很重要，一般取素数或m，若p选的不好，容易产生同义词。这是一种最简单，也是最常用的构造哈希函数的方法 …… 处理hash冲突的方法链式方法、再散列/哈希法、开放地址法、建立一个公共溢出区… Hash表查找过程查找过程中，关键码的比较次数，取决于产生冲突的多少，产生的冲突少，查找效率就高，产生的冲突多，查找效率就低。因此，影响产生冲突多少的因素，也就是影响查找效率的因素。影响产生冲突多少有以下三个因素： 散列函数是否均匀 处理冲突的方法 散列表的装填因子 散列表的装填因子（负载因子）定义为：α = 填入表中的元素个数 / 散列表的长度。α是散列表装满程度的标志因子。由于表长是定值，α与“填入表中的元素个数”成正比，所以：α越大，填入表中的元素较多，产生冲突的可能性就越大；α越小，填入表中的元素较少，产生冲突的可能性就越小。实际上，散列表的平均查找长度是装填因子α的函数，只是不同处理冲突的方法有不同的函数。 Java的HashMap解决hash冲突的方法HashMap采用一种所谓的“Hash 算法”来决定每个元素的存储位置。当程序执行 map.put(String,Obect)方法 时，系统将调用String的 hashCode() 方法得到其 hashCode 值——每个 Java 对象都有 hashCode() 方法，都可通过该方法获得它的 hashCode 值。得到这个对象的 hashCode 值之后，系统会根据该 hashCode 值来决定该元素的存储位置（对于value：我们完全可以把 Map 集合中的 value 当成 key 的附属，当系统决定了 key 的存储位置之后，value 随之保存在那里即可）。 解决hash冲突使用链表法（链表是单链表）：HashMap里面没有出现hash冲突时，没有形成单链表时，hashmap查找元素很快,get()方法能够直接定位到元素，但是出现单链表后，单个bucket 里存储的不是一个Entry，而是一个Entry链，系统只能必须按顺序遍历每个 Entry，直到找到想搜索的Entry为止——如果恰好要搜索的 Entry 位于该Entry链的最末端（该Entry是最早放入该 bucket 中），那系统必须循环到最后才能找到该元素。 HashMap的链表法解决Hash冲突 当创建 HashMap时，有一个默认的负载因子（load factor），其默认值为 0.75，这是时间和空间成本上一种折衷：增大负载因子可以减少 Hash表（就是那个 Entry 数组）所占用的内存空间，但会增加查询数据的时间开销，而查询是最频繁的的操作（HashMap的 get()与put()方法都要用到查询），减小负载因子会提高数据查询的性能，但会增加 Hash 表所占用的内存空间。","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"},{"name":"principle","slug":"principle","permalink":"http://yoursite.com/tags/principle/"},{"name":"data structure","slug":"data-structure","permalink":"http://yoursite.com/tags/data-structure/"}]},{"title":"数据库三范式","slug":"Database-Three Paradigm","date":"2017-03-19T08:34:28.000Z","updated":"2017-03-22T16:17:50.000Z","comments":true,"path":"2017/03/19/Database-Three Paradigm/","link":"","permalink":"http://yoursite.com/2017/03/19/Database-Three Paradigm/","excerpt":"","text":"虽然现在大家用单表很多，表间的关联用逻辑代码实现，但是当需要设计一个高可靠低冗余的数据库存储系统时数据库范式相关的知识还是很重要的。 第一范式（1NF）无重复的列所谓第一范式（1NF）是指数据库表的每一列都是不可分割的基本数据项，同一列中不能同时有多个值，即实体中的某个属性不能有多个值或者不能有重复的属性。如果出现重复的属性，就可能需要定义一个新的实体，新的实体由重复的属性构成，新实体与原实体之间为一对多关系。在第一范式（1NF）中表的每一行只包含一个实例的信息。简而言之，第一范式就是无重复的列。 在任何一个关系数据库中，第一范式（1NF）是对关系模式的基本要求，不满足第一范式（1NF）的数据库就不是关系数据库。在当前的任何关系数据库管理系统（DBMS）中，不可能做出不符合第一范式的数据库，因为这些DBMS不允许你把数据库表的一列再分成二列或多列。因此，你想在现有的DBMS中设计出不符合第一范式的数据库都是不可能的。 举例：学生表Student(stuNo, stuName, age, age, sex)是不符合第一范式的，age属性重复，去除重复列age以后Student(stuNo, stuName, age, sex)是符合第一范式的。 第二范式（2NF）属性完全依赖于主键（消除部分子函数依赖）第二范式是建立在第一范式的基础上，要求数据库的每个实例或行必须可以被唯一区分，这个唯一属性列被称为主键。 第二范式要求实体的属性完全依赖于主关键字，即：不能存在仅依赖主关键字的一部分属性如果存在，那么这个属性和主关键字的这一部分应该分离出来形成一个新的实体，新实体与原实体之间是一对多的关系。为实现区分通常需要为表加上一个列，以存储各个实例的唯一标识。简而言之，第二范式就是属性完全依赖于主键。（这里说的主关键字可能不只有一个，有些情况下是存在联合主键的，就是主键有多个属性。） 举例：学生表Student(stuNo, stuName, age, age, sex, courseNo, courseName, credit, score)是不符合第二范式的，联合主键(stuNo, courseNo)能够唯一确定score的属性，再看其他信息，比如stuName只需要stuNo就能够唯一确定，courseName只需要courseNo就能够唯一确定，因此这样就存在了部分依赖，不符合第二范式。如果要让学生课程成绩信息满足第二范式，那么久需要将这张表拆分成多张表，一张学生表Studnet(stuNo,stuName,age,sex)，一张课程表Course(courseNo,courseName,credit)，还有最后一张学生课程成绩表StuGrade(stuNo,courseNo,score)。 第三范式（3NF）属性不依赖于其它非主属性（消除传递依赖）第三范式是建立在第二范式的基础上，要求一个数据库表中不包含已在其它表中已包含的非主关键字。 直接举例：Employee(emp_id,emp_name,emp_age,dept_id,dept_name,dept_info)。这张员工信息表的主键是emp_id，因为这个属性能够唯一确定其他所有属性，比如知道员工编号emp_id以后，肯定能够知道员工姓名，所属部门编号，部门名称和部门介绍。所以这里dept_id不是主属性，而是非主属性。但是，我们又可以发现dept_name,dept_info这两个属性也可以由dept_id这个非主属性决定，即dept_name依赖dept_id，而dept_id依赖emp_id，这样就存在了传递依赖。而且我们可以看出传递依赖的一个明显缺点就是数据冗余非常严重。那么如何解决传递依赖问题，其实非常简单，我们只需要将dept_name,dept_info这连个属性删除就可以了，即Employee(emp_id,emp_name,emp_age,dept_id)，然后再创建一个部门表Dept(dept_id,dept_name,dept_info)。（外键的思想） 思考 数据库的连接会带来一部分的性能损失 并不是数据库的范式越高越好 需要在数据冗余与范式之间走出权衡，在实际的数据库开发过程中，往往会允许一部分的数据冗余来减少数据库的连接","categories":[{"name":"Database","slug":"Database","permalink":"http://yoursite.com/categories/Database/"}],"tags":[{"name":"database","slug":"database","permalink":"http://yoursite.com/tags/database/"},{"name":"standard","slug":"standard","permalink":"http://yoursite.com/tags/standard/"}]},{"title":"设计模式-单例模式","slug":"Design-Pattern-Design Pattern","date":"2017-03-16T16:00:42.000Z","updated":"2017-03-22T16:19:58.000Z","comments":true,"path":"2017/03/17/Design-Pattern-Design Pattern/","link":"","permalink":"http://yoursite.com/2017/03/17/Design-Pattern-Design Pattern/","excerpt":"","text":"单例模式是最简单的一种常用设计模式，单例模式需要确保一个类只有一个实例，这个类称为单例类（1、单例类只有一个实例，2、这个类必须自行创建这个实例，3、这个类必须自行向整个系统提供这个实例），像资源管理器（打印机）、数据库连接池等都是单例模式的实际应用。 基本原则Java实现单例模式一般需要遵循3个原则： 私有化构造方法，保证外部类无法创建类实例 私有的静态的类型引用，保证只有一个变量引用 提供获取实例的方法getInstance() 实现方法Java中单例模式有以下5种写法：恶汉式、懒汉式、双重校验锁、静态内部类、枚举类型的单例模式，下面分别介绍以下它们的Java实现和优缺点。 恶汉式在类加载的时候就创建了实例，简单，不存在线程安全的问题，缺点是：在不需要的对象的时候也白白创建了对象，造成资源浪费。 12345678910class Singleton &#123; //恶汉式 private static final Singleton singleton = new Singleton(); //在类加载的时候就创建了对象 private Singleton() &#123; &#125; public static Singleton getInstance() &#123; return singleton; &#125;&#125; 懒汉式在需要对象的时候才创建对象，缺点：可能造成线程不安全的问题。 12345678910111213class Singleton2 &#123; //懒汉式 private static Singleton2 singleton2 = null; private Singleton2() &#123; &#125; public static Singleton2 getInstance() &#123; //getInstance()方法可能出现线程安全问题 if(singleton2 == null) &#123; singleton2 = new Singleton2(); &#125; return singleton2; &#125;&#125; 双重校验锁双重校验锁方法是在懒汉式写法上的改进，为了解决懒汉式可能出现的线程安全问题，给getInstance()方法加上同步锁，如下： 12345678public static Singleton2 getInstance() &#123; synchronized (Singleton2.class) &#123; // 加锁 if(singleton2 == null) &#123; singleton2 = new Singleton2(); &#125; &#125; return singleton2;&#125; 但是这种方式效率很低下，会有很多的加锁操作，所以出现兼顾效率和线程安全的写法：双重检查锁，在synchronized之前做一次singleton == null判断可以减少很多加锁操作，极大提升执行效率： 1234567891011121314151617class Singleton3 &#123; // 双重校验锁 private static volatile Singleton3 singleton = null; private Singleton3() &#123; &#125; public static Singleton3 getInstance() &#123; if (singleton == null) &#123; // 避免每次都调用加锁 synchronized (Singleton3.class) &#123; if (singleton == null) &#123; singleton = new Singleton3(); &#125; &#125; &#125; return singleton; &#125;&#125; PS.双重校验锁在jdk1.5以后使用volatile关键字（保证只有一个实例）才能正常达到单例效果 静态内部类静态内部类是创建单例模式的一个很好的方法，静态的内部类只会创建一次，所以是线程安全的 12345678910111213class Singleton4 &#123; // 静态的内部类(静态的内部类只会加载一次，所以是线程安全的) private static class B &#123; private static Singleton4 singleton2 = new Singleton4(); &#125; private Singleton4() &#123; &#125; public static Singleton4 getInstance() &#123; return B.singleton2; &#125;&#125; 枚举单例模式的写法编写一个包含单个元素的模具类型，枚举类型中创建的实例是线程安全的，代码极简单，也是现在很推荐的一种单例模式写法 12345678910// 调用方法Singeton5.INSTANCE.f();enum Singleton5 &#123; INSTANCE; public int i = 0; // 实例变量 public void f() &#123; // 实例方法 System.out.println(\"枚举单例模式\"); &#125;&#125; 总结恶汉式线程安全，但是不能延时加载，资源浪费；懒汉式可以延时加载，但是会存在线程安全问题，加上锁之后效率低下；双重校验锁在jdk1.5之后可以达到单例效果；静态内部类延时加载，减小内存开销，无线程安全问题；枚举不仅能够避免多线程问题，还能防止反序列化重新创建新的对象，写法简单，很好~","categories":[{"name":"Programming","slug":"Programming","permalink":"http://yoursite.com/categories/Programming/"}],"tags":[{"name":"design pattern","slug":"design-pattern","permalink":"http://yoursite.com/tags/design-pattern/"},{"name":"standard","slug":"standard","permalink":"http://yoursite.com/tags/standard/"}]},{"title":"Java垃圾回收机制","slug":"Java-GC","date":"2017-03-16T16:00:42.000Z","updated":"2017-03-19T16:43:39.000Z","comments":true,"path":"2017/03/17/Java-GC/","link":"","permalink":"http://yoursite.com/2017/03/17/Java-GC/","excerpt":"","text":"Java垃圾回收机制相对于C++的巨大改进，避免了因为程序员忘记释放内存而造成的内存溢出错误。 背景Java除了8种基本类型，其它都是引用类型。Java运行时的数据存储区有堆(Heap)和栈(Stack)，一般栈中存放非static自动变量、函数参数、表达式临时结果和函数返回值，还有对象类型的(指针)句柄，栈中的实体数据的分配和释放均是由系统自动完成的。一般堆中存放对象数据类型，堆中的实体数据是由程序显示分配的，开发者只需要在用堆分配的时候创建就行了，何时释放如何释放，都由JVM来做，不需要程序代码来显示的释放。 两种回收策略早期实现GC(Garbage Collection)的是引用计数机制，当有新的指向该对象的引用时，计数器加1，引用移除时，计数器减1，当计数器为0时，认为可以进行垃圾回收。但是这种方式当出现循环引用的时候就不行了。 JVM的处理有两种机制： “mark and sweep标记清除”这种机制下，每个对象都有标记信息，用于表示该对象是否可达。当垃圾回收时，Java程序暂停运行。JVM从根(ROOT)出发，找到可达对象，并标记(mark)，随后，JVM需要扫描整个堆，找到剩余对象，并清空这些对象所占据的内存空间。 “copy and sweep复制清除”这种机制下，堆被分为两个区域，对象总存活于两个区域中的一个。当垃圾回收启动时，Java程序暂停运行，JVM从根（ROOT）出发，找到可达对象，将可到达的对象复制到空白区域中并紧密排列，修改由于对象移动所造成的引用地址变化。最后，直接清空对象原先存活的整个区域，使其成为新的空白区域。 PS. 可以看到，”copy and sweep”需要更加复杂的操作，但也让对象可以紧密排列，避免”mark and sweep”中可能出现的空隙。在新建对象时，”copy and sweep”可以提供大块的连续空间。因此，如果对象都比较”长寿”，那么适用于”mark and sweep”。如果对象的”新陈代谢”比较活跃，那么适用于”copy and sweep”。 分代回收JVM中上面两种机制是通过分代回收(generational collection)混合在一起的。每个对象记录有它的世代(generation)信息。所谓的世代，是指该对象所经历的垃圾回收的次数。世代越久远的对象，在内存中存活的时间越久。根据对Java程序的统计观察，世代越久的对象，越不可能被垃圾回收(富人越富，穷人越穷)。因此，当我们在垃圾回收时，要更多关注那些年轻的对象。 GC分代机制 其中的永久世代(permanent generation)中存活的是Class对象。这些对象不会被垃圾回收(在Java8中已经移除了永久代，新加了一个叫元数据区的native内存区)。年轻世代(young generation)和成熟世代(tenured generation)需要进行垃圾回收。年轻世代中的对象世代较近，而成熟世代中的对象世代较久。 年轻世代又进一步分为三个区域：eden(伊甸): 新生对象存活于该区域。新生对象指从上次GC后新建的对象。from(survivor1),to(survivor2)：这两个区域大小相等，相当于copy and sweep中的两个区域。 当新建对象无法放入eden区时，将出发minor collection。JVM采用copy and sweep的策略，将eden区与from区的可到达对象复制到to区。经过一次垃圾回收，eden区和from区清空，to区中则紧密的存放着存活对象。随后，from区成为新的to区， to区成为新的from区。如果进行minor collection的时候，发现to区放不下，则将部分对象放入成熟世代。另一方面，即使to区没有满，JVM依然会移动世代足够久远的对象（15次拷贝后任然存在的对象）到成熟世代。如果成熟世代放满对象，无法移入新的对象，那么将触发major collection。JVM采用mark and sweep的策略，对成熟世代进行垃圾回收。 如果在执行垃圾回收之后，仍没有足够的内存分配，也不能再扩展，将会抛出OutOfMemoryError:Java heap space异常。 JVM对于循环引用的垃圾回收：如果其他所有对象都没有引用这两个对象，即使这两个对象相互引用，也会被GC因为JVM是从一个根对象开始查找引用的，没有任何路径可以被根对象引用的闭环也会被GC的。 补充java内存溢出的原因： 内存中加载的数据量过于庞大，如一次从数据库取出过多数据； 集合类中有对对象的引用，使用完后未清空，使得JVM不能回收； 代码中存在死循环或循环产生过多重复的对象实体。","categories":[{"name":"Java","slug":"Java","permalink":"http://yoursite.com/categories/Java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"},{"name":"principle","slug":"principle","permalink":"http://yoursite.com/tags/principle/"},{"name":"memory","slug":"memory","permalink":"http://yoursite.com/tags/memory/"}]}]}